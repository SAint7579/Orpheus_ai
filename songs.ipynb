{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.schedulers.scheduling_utils import SchedulerMixin\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np  # noqa: E402\n",
    "from PIL import Image  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import librosa  # noqa: E402\n",
    "\n",
    "    _librosa_can_be_imported = True\n",
    "    _import_error = \"\"\n",
    "except Exception as e:\n",
    "    _librosa_can_be_imported = False\n",
    "    _import_error = (\n",
    "        f\"Cannot import librosa because {e}. Make sure to correctly install librosa to be able to install it.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mel(ConfigMixin, SchedulerMixin):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x_res (`int`): x resolution of spectrogram (time)\n",
    "        y_res (`int`): y resolution of spectrogram (frequency bins)\n",
    "        sample_rate (`int`): sample rate of audio\n",
    "        n_fft (`int`): number of Fast Fourier Transforms\n",
    "        hop_length (`int`): hop length (a higher number is recommended for lower than 256 y_res)\n",
    "        top_db (`int`): loudest in decibels\n",
    "        n_iter (`int`): number of iterations for Griffin Linn mel inversion\n",
    "    \"\"\"\n",
    "\n",
    "    config_name = \"mel_config.json\"\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_res: int = 256,\n",
    "        y_res: int = 256,\n",
    "        sample_rate: int = 22050,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        top_db: int = 80,\n",
    "        n_iter: int = 32,\n",
    "    ):\n",
    "        self.hop_length = hop_length\n",
    "        self.sr = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.top_db = top_db\n",
    "        self.n_iter = n_iter\n",
    "        self.set_resolution(x_res, y_res)\n",
    "        self.audio = None\n",
    "\n",
    "        if not _librosa_can_be_imported:\n",
    "            raise ValueError(_import_error)\n",
    "\n",
    "    def set_resolution(self, x_res: int, y_res: int):\n",
    "        \"\"\"Set resolution.\n",
    "\n",
    "        Args:\n",
    "            x_res (`int`): x resolution of spectrogram (time)\n",
    "            y_res (`int`): y resolution of spectrogram (frequency bins)\n",
    "        \"\"\"\n",
    "        self.x_res = x_res\n",
    "        self.y_res = y_res\n",
    "        self.n_mels = self.y_res\n",
    "        self.slice_size = self.x_res * self.hop_length - 1\n",
    "\n",
    "    def load_audio(self, audio_file: str = None, raw_audio: np.ndarray = None):\n",
    "        \"\"\"Load audio.\n",
    "\n",
    "        Args:\n",
    "            audio_file (`str`): must be a file on disk due to Librosa limitation or\n",
    "            raw_audio (`np.ndarray`): audio as numpy array\n",
    "        \"\"\"\n",
    "        if audio_file is not None:\n",
    "            self.audio, _ = librosa.load(audio_file, mono=True, sr=self.sr)\n",
    "        else:\n",
    "            self.audio = raw_audio\n",
    "\n",
    "        # Pad with silence if necessary.\n",
    "        if len(self.audio) < self.x_res * self.hop_length:\n",
    "            self.audio = np.concatenate([self.audio, np.zeros((self.x_res * self.hop_length - len(self.audio),))])\n",
    "\n",
    "    def get_number_of_slices(self) -> int:\n",
    "        \"\"\"Get number of slices in audio.\n",
    "\n",
    "        Returns:\n",
    "            `int`: number of spectograms audio can be sliced into\n",
    "        \"\"\"\n",
    "        return len(self.audio) // self.slice_size\n",
    "\n",
    "    def get_audio_slice(self, slice: int = 0) -> np.ndarray:\n",
    "        \"\"\"Get slice of audio.\n",
    "\n",
    "        Args:\n",
    "            slice (`int`): slice number of audio (out of get_number_of_slices())\n",
    "\n",
    "        Returns:\n",
    "            `np.ndarray`: audio as numpy array\n",
    "        \"\"\"\n",
    "        return self.audio[self.slice_size * slice : self.slice_size * (slice + 1)]\n",
    "\n",
    "    def get_sample_rate(self) -> int:\n",
    "        \"\"\"Get sample rate:\n",
    "\n",
    "        Returns:\n",
    "            `int`: sample rate of audio\n",
    "        \"\"\"\n",
    "        return self.sr\n",
    "\n",
    "    def audio_slice_to_image(self, slice: int, ref=np.max) -> Image.Image:\n",
    "        \"\"\"Convert slice of audio to spectrogram.\n",
    "\n",
    "        Args:\n",
    "            slice (`int`): slice number of audio to convert (out of get_number_of_slices())\n",
    "\n",
    "        Returns:\n",
    "            `PIL Image`: grayscale image of x_res x y_res\n",
    "        \"\"\"\n",
    "        S = librosa.feature.melspectrogram(\n",
    "            y=self.get_audio_slice(slice), sr=self.sr, n_fft=self.n_fft, hop_length=self.hop_length, n_mels=self.n_mels\n",
    "        )\n",
    "        log_S = librosa.power_to_db(S, ref=ref, top_db=self.top_db)\n",
    "        bytedata = (((log_S + self.top_db) * 255 / self.top_db).clip(0, 255) + 0.5).astype(np.uint8)\n",
    "        image = Image.fromarray(bytedata)\n",
    "        return image\n",
    "\n",
    "    def image_to_audio(self, image: Image.Image) -> np.ndarray:\n",
    "        \"\"\"Converts spectrogram to audio.\n",
    "\n",
    "        Args:\n",
    "            image (`PIL Image`): x_res x y_res grayscale image\n",
    "\n",
    "        Returns:\n",
    "            audio (`np.ndarray`): raw audio\n",
    "        \"\"\"\n",
    "        bytedata = np.frombuffer(image.tobytes(), dtype=\"uint8\").reshape((image.height, image.width))\n",
    "        log_S = bytedata.astype(\"float\") * self.top_db / 255 - self.top_db\n",
    "        S = librosa.db_to_power(log_S)\n",
    "        audio = librosa.feature.inverse.mel_to_audio(\n",
    "            S, sr=self.sr, n_fft=self.n_fft, hop_length=self.hop_length, n_iter=self.n_iter\n",
    "        )\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create an instance of Mel\n",
    "mel = Mel()\n",
    "\n",
    "# Step 2: Load the audio file\n",
    "audio_file = \"C:/VS code projects/Orpheus-2/audio/nvg.wav\"\n",
    "mel.load_audio(audio_file)\n",
    "\n",
    "# Step 3: Determine the number of slices\n",
    "num_slices = mel.get_number_of_slices()\n",
    "\n",
    "# Step 4: Convert each slice to an image\n",
    "images = []\n",
    "for i in range(num_slices):\n",
    "    img = mel.audio_slice_to_image(i)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "# Step 1: Create an instance of Mel\n",
    "mel = Mel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the audio file\n",
    "audio_file = \"C:/VS code projects/Orpheus-2/downloads/001311.mp3\"\n",
    "mel.load_audio(audio_file)\n",
    "\n",
    "# Step 3: Determine the number of slices\n",
    "num_slices = mel.get_number_of_slices()\n",
    "# Step 4: Convert each slice to an image\n",
    "img = mel.audio_slice_to_image(3)\n",
    "images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[9].save(\"C:/VS code projects/Orpheus-2/downloads/9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sample rate (e.g., 44100)\n",
    "sample_rate = 22050\n",
    "\n",
    "# Save the audio array as a temporary WAV file\n",
    "temp_wav_file = \"temp.wav\"\n",
    "wavfile.write(temp_wav_file, sample_rate, mel.image_to_audio(images[3]))\n",
    "\n",
    "# Set the output MP3 file path\n",
    "output_mp3_file = \"audio/output.mp3\"\n",
    "\n",
    "# Load the temporary WAV file\n",
    "wav_data, sr = sf.read(temp_wav_file)\n",
    "\n",
    "# Convert the WAV data to MP3 format\n",
    "sf.write(output_mp3_file, wav_data, sample_rate, format=\"MP3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\aniru\\anaconda3\\envs\\py39\\lib\\site-packages (2.9.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from io import BytesIO\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(database=\"orpheus\", user=\"postgres\", password=\"1234\", host=\"localhost\", port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Assuming you have a table named 'images' with columns 'id' (serial primary key) and 'image_data' (bytea)\n",
    "table_name = \"songs\"\n",
    "\n",
    "# Convert PIL.Image.Image object to bytes\n",
    "image = Image.open(\"C:/VS code projects/Orpheus-2/downloads/0.png\")  # Replace with your actual Image object\n",
    "image_bytes = BytesIO()\n",
    "image.save(image_bytes, format=\"PNG\")\n",
    "image_bytes = image_bytes.getvalue()\n",
    "\n",
    "# Insert the image data into the database\n",
    "cur.execute(f\"INSERT INTO {table_name} (song,id) VALUES (%s,%s)\", (image_bytes,10))\n",
    "\n",
    "# Commit the changes and close the database connection\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from io import BytesIO\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn = psycopg2.connect(database=\"orpheus\", user=\"postgres\", password=\"1234\", host=\"localhost\", port=\"5432\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Assuming you have a table named 'images' with columns 'id' (serial primary key) and 'image_data' (bytea)\n",
    "table_name = \"music\"\n",
    "image_id = 18  # Replace with the actual ID of the image you want to retrieve\n",
    "\n",
    "# Retrieve the image data from the database\n",
    "cur.execute(f\"SELECT songs FROM {table_name} WHERE encoding = %s\", (image_id,))\n",
    "result = cur.fetchone()\n",
    "\n",
    "# Convert the bytea data to PIL.Image.Image object\n",
    "image_bytes = BytesIO(result[0])\n",
    "image = Image.open(image_bytes)\n",
    "\n",
    "# Close the database connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Use the image as needed\n",
    "image.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
