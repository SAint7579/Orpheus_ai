{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541e9dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GP65\\anaconda3\\lib\\site-packages\\llvmlite\\llvmpy\\__init__.py:3: UserWarning: The module `llvmlite.llvmpy` is deprecated and will be removed in the future.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GP65\\anaconda3\\lib\\site-packages\\llvmlite\\llvmpy\\core.py:8: UserWarning: The module `llvmlite.llvmpy.core` is deprecated and will be removed in the future. Equivalent functionality is provided by `llvmlite.ir`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\GP65\\anaconda3\\lib\\site-packages\\llvmlite\\llvmpy\\passes.py:17: UserWarning: The module `llvmlite.llvmpy.passes` is deprecated and will be removed in the future. If you are using this code, it should be inlined into your own project.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from scipy.signal import resample\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.fft import fft,fftfreq\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## Loading Model\n",
    "model = keras.models.load_model('D:/Projects/Orpheus_ai/DataSet/model_save_logs/Saved Models/VQVAE(7K)_normalized80lowrez_5e-03recloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1abb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_level_db = -80\n",
    "sr = 22050\n",
    "hop_length = 1024\n",
    "n_fft = hop_length*4\n",
    "SAVE_PATH = 'D:/Projects/Orpheus_ai/DataSet/audio_recreation[VQVAE(7K)]/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f01da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(S):\n",
    "    return np.clip((((S - min_level_db) / -min_level_db)*2.)-1., -1, 1)\n",
    "\n",
    "def denormalize(S):\n",
    "    return (((np.clip(S, -1, 1)+1.)/2.) * -min_level_db) + min_level_db\n",
    "\n",
    "def get_similarity_score(y, yhat, sr=sr):\n",
    "    \n",
    "    '''\n",
    "    Input: Original and Recreated Signal\n",
    "    Output: Cosine Similarity of the FFT of the signals\n",
    "    '''\n",
    "    def get_fft(signal,sr,l=205000):\n",
    "        '''\n",
    "        Wrapper for FFT creation\n",
    "        '''\n",
    "    \n",
    "        ft = np.abs(fft(signal))\n",
    "        freq = fftfreq(l, 1.0 / sr)\n",
    "        return ft[:l//2],freq[:l//2]\n",
    "\n",
    "    def mmxs(d):\n",
    "        '''\n",
    "        Min-Max Normalization\n",
    "        '''\n",
    "        return (d-d.min())/(d.max()-d.min())\n",
    "    \n",
    "    f,freqs = get_fft(mmxs(y),sr)\n",
    "    f_hat,_ = get_fft(mmxs(yhat),sr)   \n",
    "    \n",
    "    audible_indexes = [np.logical_and(freqs>12,freqs<28000)]\n",
    "    \n",
    "    f, f_hat = f[audible_indexes], f_hat[audible_indexes]\n",
    "    \n",
    "    absolute = (np.mean((f-f_hat)**2))**0.5 ## Maybe--Bit Ambigious\n",
    "    spatial =  1 - cosine(f,f_hat)\n",
    "    \n",
    "    return absolute,spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c949171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = glob('D:/Projects/Orpheus_ai/DataSet/Spectrograms/HalfMEL_dbscale/*')\n",
    "song_location = pd.read_csv('D:/Projects/Orpheus_ai/DataSet/main_dataframe.csv',index_col=['track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581de24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7107784682422c92d540127f33bd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9599 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GP65\\AppData\\Roaming\\Python\\Python38\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "<ipython-input-3-2679d21e80b0>:33: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  f, f_hat = f[audible_indexes], f_hat[audible_indexes]\n",
      "C:\\Users\\GP65\\AppData\\Roaming\\Python\\Python38\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    full_dataframe = pd.read_csv('D:/Projects/Orpheus_ai/DataSet/recreation_quality.csv',index_col=['track_id'])\n",
    "    stin = len(full_dataframe)\n",
    "except:\n",
    "    full_dataframe = None\n",
    "    stin = 0\n",
    "    \n",
    "dataframe = []\n",
    "for i,path in tqdm(list(enumerate(data_paths[stin:]))):\n",
    "    try:\n",
    "        ## Loading Original Data\n",
    "        name = path.split(\"\\\\\")[-1].split('.')[0]\n",
    "        instrumental_path = song_location.loc[int(name)]['instrumental_path']\n",
    "        ori_signal, _ = librosa.load(instrumental_path)\n",
    "        ori_signal = ori_signal[:sr*10]\n",
    "        S = np.load(path)\n",
    "        assert S.shape == (128,216)\n",
    "        \n",
    "        ## Getting Model Prediction\n",
    "        model_S = normalize(np.expand_dims(np.array([S]),axis=-1))\n",
    "        S_hat = denormalize(model.predict(model_S,verbose=0)[0,:,:,0])\n",
    "\n",
    "        ## Inverting with Griffin Lim\n",
    "        spec_signal = librosa.feature.inverse.mel_to_audio(librosa.db_to_power(S),sr=sr,n_fft=n_fft,hop_length=hop_length)\n",
    "        spec_hat_signal = librosa.feature.inverse.mel_to_audio(librosa.db_to_power(S_hat),sr=sr,n_fft=n_fft,hop_length=hop_length)\n",
    "\n",
    "        abs_mel, spa_mel = get_similarity_score(ori_signal,spec_signal)\n",
    "        abs_mel_hat, spa_mel_hat = get_similarity_score(ori_signal,spec_hat_signal)\n",
    "        \n",
    "        ## Saving Song\n",
    "        np.save(f'{SAVE_PATH}{name}.npy',spec_hat_signal)\n",
    "        \n",
    "        ## Adding Data\n",
    "        dataframe.append([int(name),f'{SAVE_PATH}{name}.npy',abs_mel,spa_mel,abs_mel_hat,spa_mel_hat])\n",
    "        \n",
    "        if i%5 == 0:\n",
    "            temp_df = pd.DataFrame(dataframe,columns=['track_id','path','abs_mel','spa_mel','abs_mel_hat','spa_mel_hat'])\n",
    "            temp_df.set_index('track_id',inplace=True)\n",
    "            \n",
    "            if full_dataframe is None:\n",
    "                full_dataframe = temp_df\n",
    "            else:\n",
    "                full_dataframe = pd.concat([full_dataframe,temp_df])\n",
    "                \n",
    "            full_dataframe.to_csv('D:/Projects/Orpheus_ai/DataSet/recreation_quality.csv')\n",
    "            \n",
    "            dataframe = []\n",
    "        \n",
    "    except AssertionError:\n",
    "        print(f\"{path} Size exception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460d8c1",
   "metadata": {},
   "source": [
    "### Song Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20a1d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-65dfa290845d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/Projects/Orpheus_ai/DataSet/audio_recreation[VQVAE(7K)]/000002.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\lib\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "file= np.load('D:/Projects/Orpheus_ai/DataSet/audio_recreation[VQVAE(7K)]/000002.npy')\n",
    "ipd.Audio(file, rate=22016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e971bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(file.shape[0])//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a41ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
